{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "mnnmfrom numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### move to spacy and do lematization later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv('Cleaned-P&P data.csv')\n",
    "\n",
    "blanks = []  # start with an empty list`\n",
    "\n",
    "for i,c,d,inc,sd in df1.itertuples():  # iterate over the DataFrame\n",
    "        if c == 'O' or c=='E':         # test 'review' for whitespace\n",
    "            blanks.append(i)     # add matching index numbers to the list\n",
    "df1.drop(blanks, inplace=True)\n",
    "df1[\"desc\"] = df1[\"short_des\"] + '. ' + df1[\"desc\"]\n",
    "df1.reset_index(drop=True,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df2 = pd.read_csv('Cleaned-P&P data.csv')\n",
    "blanks2 = []  # start with an empty list`\n",
    "\n",
    "for i,c,d,inc,sd in df2.itertuples():  # iterate over the DataFrame\n",
    "        if c == 'O' or c=='E':         # test 'review' for whitespace\n",
    "            blanks2.append(i)     # add matching index numbers to the list\n",
    "df2.drop(blanks2, inplace=True)\n",
    "df2.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([df1, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "490"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the texts\n",
    "import re\n",
    "corpus = []\n",
    "all_words = []\n",
    "max_len=0\n",
    "for i in range(0, 490):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', dataset['desc'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = ' '.join(review)\n",
    "    \n",
    "    review = nlp(review)\n",
    "    review = [word.text for word in review]\n",
    "    all_words.append(review) \n",
    "    if len(review) > max_len:\n",
    "        max_len = len(review)\n",
    "    ds = ' '.join(review)\n",
    "#    for word2vec we want an array of vectors\n",
    "    corpus.append(ds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n"
     ]
    }
   ],
   "source": [
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = [j for sub in all_words for j in sub] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "763"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words = set(all_words)\n",
    "print(len(unique_words))\n",
    "vocab_length = len(unique_words) + 10\n",
    "vocab_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>desc</th>\n",
       "      <th>inc_num</th>\n",
       "      <th>short_des</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P</td>\n",
       "      <td>y2684992. good afternoon,\\r\\n\\r\\nthis customer...</td>\n",
       "      <td>INC0809260</td>\n",
       "      <td>y2684992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "      <td>delivery pass needs removing on staff accounts...</td>\n",
       "      <td>INC0808628</td>\n",
       "      <td>delivery pass needs removing on staff accounts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "      <td>delivery pass needs removing on staff accounts...</td>\n",
       "      <td>INC0807253</td>\n",
       "      <td>delivery pass needs removing on staff accounts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P</td>\n",
       "      <td>customer being charged for delivery. customer:...</td>\n",
       "      <td>INC0806836</td>\n",
       "      <td>customer being charged for delivery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P</td>\n",
       "      <td>website/web shop issues. short description:tam...</td>\n",
       "      <td>INC0805994</td>\n",
       "      <td>website/web shop issues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                               desc     inc_num  \\\n",
       "0     P  y2684992. good afternoon,\\r\\n\\r\\nthis customer...  INC0809260   \n",
       "1     R  delivery pass needs removing on staff accounts...  INC0808628   \n",
       "2     R  delivery pass needs removing on staff accounts...  INC0807253   \n",
       "3     P  customer being charged for delivery. customer:...  INC0806836   \n",
       "4     P  website/web shop issues. short description:tam...  INC0805994   \n",
       "\n",
       "                                           short_des  \n",
       "0                                           y2684992  \n",
       "1  delivery pass needs removing on staff accounts...  \n",
       "2  delivery pass needs removing on staff accounts...  \n",
       "3                customer being charged for delivery  \n",
       "4                            website/web shop issues  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'INC0758972'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['inc_num'][49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "684"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus[49])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import Normalizer\n",
    "# transformer = Normalizer().fit(padded_sent)\n",
    "# padded_sentences = transformer.transform(padded_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'padded_sentences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-4a4af5c2b23d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpadded_sentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'padded_sentences' is not defined"
     ]
    }
   ],
   "source": [
    "print(padded_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "word_tokenizer = Tokenizer()\n",
    "word_tokenizer.fit_on_texts(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "754"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_results = word_tokenizer.texts_to_matrix(corpus, mode='binary')\n",
    "len(one_hot_results[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sentences = word_tokenizer.texts_to_sequences(corpus)\n",
    "len(embedded_sentences[49])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_sentences = pad_sequences(embedded_sentences, max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "\n",
    "embeddings_dictionary = dict()\n",
    "glove_file = open(r'C:\\Users\\AVNEET\\Desktop\\glove.6B.100d.txt', encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary [word] = vector_dimensions\n",
    "\n",
    "glove_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = zeros((vocab_length, 100))\n",
    "\n",
    "for word, index in word_tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_matrix[752])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(488, 727)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# vectorizer = TfidfVectorizer()\n",
    "\n",
    "# X_train_tfidf = vectorizer.fit_transform(corpus) # remember to use the original X_train set\n",
    "# X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<488x727 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 12476 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\AVNEET\\miniconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_length,100,weights=[embedding_matrix], input_length=max_len,trainable=False))\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(vocab_length, input_dim=30, activation='softmax'))\n",
    "# model.add(Dense(vocab_length, input_dim=30, activation='softmax'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 114, 100)          76200     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 11400)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 22802     \n",
      "=================================================================\n",
      "Total params: 99,002\n",
      "Trainable params: 22,802\n",
      "Non-trainable params: 76,200\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cldict = {'P':1 , 'R':0}\n",
    "dataset['Class Label'] = dataset['class'].map(cldict)\n",
    "label_series = pd.Series(dataset['Class Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(488, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "class_label = np.array(label_series)\n",
    "y = class_label\n",
    "y = to_categorical(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = padded_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\AVNEET\\miniconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19f82af8608>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=300, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 0s 122us/step\n",
      "Accuracy: 98.648649\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.99999785423279\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "95.99999785423279\n",
      "100.0\n",
      "100.0\n",
      "95.83333134651184\n",
      "95.83333134651184\n",
      "95.83333134651184\n",
      "100.0\n",
      "100.0\n",
      "95.83333134651184\n",
      "91.66666865348816\n",
      "100.0\n",
      "91.66666865348816\n",
      "95.83333134651184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "97.72499948740005"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "k_fold = KFold(n_splits=20, shuffle=True, random_state=7)\n",
    "acc_lst=[]\n",
    "for tr, test in k_fold.split(X, y):\n",
    "    loss, accur = model.evaluate(X[test], y[test], verbose=0)   \n",
    "    accur=accur*100\n",
    "    print(accur)\n",
    "    acc_lst.append(accur)\n",
    "np.mean(acc_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.4521551e-05, 9.9990547e-01],\n",
       "       [4.0384810e-04, 9.9959618e-01],\n",
       "       [9.9384270e-05, 9.9990058e-01],\n",
       "       [9.9999154e-01, 8.4906414e-06],\n",
       "       [8.2660872e-01, 1.7339128e-01]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('P&PGloVe.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "P [[0.01869247 0.9813075 ]]\n"
     ]
    }
   ],
   "source": [
    "#strin = 'please add the delivery subscription'\n",
    "# pad = re.sub('[^a-zA-Z]', ' ', pad)\n",
    "vocab_length = 762\n",
    "max_len = 114\n",
    "pad = strin.lower()\n",
    "pad = pad.split()\n",
    "pad = ' '.join(pad)\n",
    "pad = nlp(pad)\n",
    "pad = [word.text for word in pad]\n",
    "pad = ' '.join(pad)\n",
    "emb = [one_hot(pad, vocab_length)]\n",
    "pady = pad_sequences(emb, max_len, padding='post')\n",
    "\n",
    "x = model.predict_classes(pady)\n",
    "print(x)\n",
    "if x[0] == 1:\n",
    "    print('P', model.predict(pady))\n",
    "    \n",
    "else: \n",
    "        print('R', model.predict(pady))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "strin = 'Hi the delivery passes need removing from these staff accounts This is still being to Staff accounts for Â£0 01 please can you remove this Thank You'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[182   8]\n",
      " [  3 295]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Create a prediction set:\n",
    "predictions = model.predict_classes(X)\n",
    "\n",
    "# Print a confusion matrix\n",
    "print(metrics.confusion_matrix(y.argmax(axis=1),predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class:[1] [[5.175987e-04 9.994824e-01]] Index is : 5\n",
      "predicted class:[1] [[0.16320924 0.83679074]] Index is : 10\n",
      "predicted class:[1] [[0.39117888 0.60882115]] Index is : 14\n",
      "predicted class:[1] [[0.01174793 0.9882521 ]] Index is : 30\n",
      "predicted class:[1] [[0.37375617 0.6262438 ]] Index is : 36\n",
      "predicted class:[1] [[9.4522002e-05 9.9990547e-01]] Index is : 52\n",
      "predicted class:[0] [[0.94681954 0.05318044]] Index is : 63\n",
      "predicted class:[1] [[0.18990098 0.81009907]] Index is : 74\n",
      "predicted class:[1] [[0.06214963 0.93785036]] Index is : 77\n"
     ]
    }
   ],
   "source": [
    "3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ** delivery pass needs removing on orders supra dba req please can the delivery pass be removed from the attached staff accounts thank you **** 9 INC0793103\n",
      "4 ** annual delivery pass cancelled please can the annual delivery pass service be removed from customers account a thanks **** 11 INC0791140\n",
      "5 ** a a hi this is a new staff account it is showing as free delivery can this be removed please thanks chris **** 117 INC0690294\n",
      "8 ** delivery pass needs removing on staff accounts supra dba req please can you remove the delivery pass from the attached staff accounts thank you **** 124 INC0684243\n",
      "7 ** delivery subscription needs removing u please can you remove the delivery subscription from account thank you **** 193 INC0622277\n",
      "3 ** customer wishes to cancel annual delivery t please can you remove the delivery subscription service from this account thanks **** 195 INC0622190\n",
      "6 ** annual delivery pass not working please apply delivery pass to account t purchased thanks **** 211 INC0595802\n",
      "2 ** please can the attached annual delivery pass be removed from the attached staff accounts thank you **** 272 INC0779242\n",
      "0 ** hi the delivery passes need removing from these staff accounts this is still being added to staff accounts for pleasecan you remove this thank you **** 479 INC0532119\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "s=0\n",
    "for j in range(0,488):\n",
    "    for k in range(0,9):\n",
    "        if (np.array_equal(arr[k], padded_sentences[j])):\n",
    "            print(k, '**',corpus[j],'****', j , dataset['inc_num'][j])\n",
    "print(s)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n"
     ]
    }
   ],
   "source": [
    "if (arr[0] == padded_sentences[0]).all:\n",
    "    print('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(padded_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114,)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sentences[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(arr[0], padded_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
